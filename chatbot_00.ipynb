{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b52d915-1ec7-45ba-8d85-a5a51c039d9a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c48f5aa4-a620-4cb8-8a10-c488e2bb91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8e72b2-c3aa-4fd7-8b19-446f0eb45541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "53ed48a4-9afc-4e7c-854c-64f819badb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Langchain import statements\\nfrom langchain.embeddings import OpenAIEmbeddings\\nfrom langchain.vectorstores import Chroma\\nfrom langchain.chains import RetrievalQA\\nfrom langchain.chat_models import ChatOpenAI'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Langchain import statements\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d0ff5d-5a35-4d53-bed3-dfceeac4b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment file explicitly\n",
    "from pathlib import Path\n",
    "dotenv_path = Path('/Users/kyli/Documents/GitHub/lab_gpt/.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# Access variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_maps_api_key = os.getenv(\"GOOGLE_MAPS_API_KEY\")\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d5ee5d-e0af-4fb6-bd59-8d7ce1a6adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tkinter import statements\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e8f374-c320-4ba2-9f1b-4499d5722861",
   "metadata": {},
   "source": [
    "# Document loading and chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396e0e88-3a21-4a94-94fb-54f02069c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and preprocess documents\n",
    "loader = PyPDFLoader(\"/Users/kyli/Desktop/lab_gpt_example_docs/01_pathophys_tbi.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5310c74f-f3f1-45ea-8010-8a284a696ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load documents into a variable called documents, which is a list of document objects\n",
    "#Attributes of each document object are page_content and metadata\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770deb6f-9217-40d4-a986-30dd70df8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the text using Recursive Character Text Splitter - other text splitting algos available\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d96ec4-a91f-4588-953e-e397c6a1c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign each chunk of text to a different list item in docs (I think)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b891fae2-5439-4a7b-9551-f5b7fb7da352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/kyli/Desktop/lab_gpt_example_docs/01_pathophys_tbi.pdf', 'page': 0}, page_content='dependence. However, despite a spectrum of \\nclinical features and symptoms, the pathophysi-\\nological processes that occur after TBI are simi-\\nlar across most injuries and differ primarily in the \\nmagnitude and duration of the pathophysiology \\n[3]. It is necessary to note that this is not the case \\nK. R. Giordano · J. Lifshitz (*) \\nBarrow Neurological Institute at Phoenix Children’s \\nHospital, Phoenix, AZ, USA \\nDepartment of Child Health, University of Arizona \\nCollege of Medicine – Phoenix, Phoenix, AZ, USA \\nPhoenix V A Health Care System, Phoenix, AZ, USA\\ne-mail: jlifshitz@email.arizona.edu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at one chunk of text\n",
    "docs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e6bba44-4ee0-4544-b451-d616fc2b0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import text=splitting algorithm - there ae multiple options available\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0872f3a0-fe04-411e-9e68-0b02dc4b61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many characters in each text chunk\n",
    "chunk_size = 26\n",
    "#How many characters overlap between each text chunk\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c691a2b-5d85-4fd6-ad84-ab9b81b375d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of RecursiveCharacterTextSplitter, assign to variable r_splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af45fdb4-0027-4e8f-a79b-6d5805818c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save each chunk to a list called splits\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4811c86c-82f7-40ab-8a4e-62bc74cee84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1449"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce3904-c115-4499-a777-8f482a0ed6bc",
   "metadata": {},
   "source": [
    "# Document storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "76091b22-f77f-42bf-abe5-5bca6ce63453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an embedding model to store text chunks in vector database\n",
    "#embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e64295e6-4e0a-42da-975c-ffc05e75122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40fe7525-439d-499f-be06-38e083722a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate OpenAI model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b5a36005-f951-4504-83bb-3674834c2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a non-persistent Chroma database\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"test_docs\", \n",
    "    embedding_function=OpenAIEmbeddings(openai_api_key=openai_api_key),\n",
    "    persist_directory=None  # Non-persistent mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417c389-9e89-4384-8313-32c16e5a0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "test_doc_01=documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579af3e6-e2cf-44ec-872e-f6df7a87f0ea",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68200c-0d1e-43b6-829a-864210c70732",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_doc_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421bbee-2d22-4b60-8b65-eed6c9dc05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19434fab-db81-40af-8d04-5893614c0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = retriever.invoke(\"How long does post-percussive syndrome last?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42963133-9923-42cc-9b83-ce7e52c2ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97924f3-55a3-4e69-aaff-13816e846c6c",
   "metadata": {},
   "source": [
    "Lots of chatbot how-to's: \n",
    "\n",
    "https://python.langchain.com/docs/how_to/#qa-with-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8698a2-c300-4d9f-abed-fd5ec723a48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lab_gpt_env)",
   "language": "python",
   "name": "lab_gpt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
